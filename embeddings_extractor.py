import torch
import numpy as np


def load_model():
  ''' Loads the model from the github repo and obtains just the feature encoder. '''

  repo = 'OxWearables/ssl-wearables'
  # class_num não interessa para extrair features; mas o hub pede este arg
  model = torch.hub.load(repo, 'harnet5', class_num=5, pretrained=True)
  model.eval()

  # Passo crucial: ficar só com a parte auto-supervisionada
  # O README diz que há um 'feature_extractor' (pré-treinado) e um 'classifier' (não treinado). :contentReference[oaicite:14]{index=14}
  feature_encoder = model.feature_extractor
  feature_encoder.to("cpu")
  feature_encoder.eval()

  return feature_encoder


def resample_to_30hz_5s(acc_xyz, fs_in_hz):
    """
    acc_xyz: np.ndarray shape (N, 3) em m/s^2 (ou g), amostrado a fs_in_hz (float)
    devolve:
      acc_resampled: np.ndarray shape (M, 3) já a 30 Hz
      fs_target: 30.0
    """
    fs_target = 30.0
    win_size = 5 # in seconds
    t_in = np.arange(acc_xyz.shape[0]) / fs_in_hz
    t_out = np.arange(0, win_size, 1.0/fs_target)

    acc_resampled = np.zeros((len(t_out), 3), dtype=np.float32)
    for axis in range(3):
        acc_resampled[:, axis] = np.interp(t_out, t_in, acc_xyz[:, axis])

    return acc_resampled, fs_target


def acc_segmentation(data):
  ''' Estract ACC segments and their activities '''

  TIMESTAMP_COL = 10
  MIN_SEGMENT_SIZE = 20
  fs_in_hz = 51.5
  win_size = 5000
  start_time = data[0,TIMESTAMP_COL]
  end_time = start_time + win_size

  activities = []
  segments = []

  while end_time < data[-1,TIMESTAMP_COL]:
    mask = (data[:,TIMESTAMP_COL] >= start_time) & (data[:,TIMESTAMP_COL] < end_time)

    if np.sum(mask) > MIN_SEGMENT_SIZE and np.all(data[mask, -1] == data[mask, -1][0]):

      acc_xyz = data[mask,1:4]
      activity = data[mask, -1][0]
      
      activities.append(activity)
      segments.append( acc_xyz )
      

    start_time = end_time - win_size/2
    end_time = start_time + win_size
  
  
  return segments, activities


if __name__ == "__main__":
  # load example file to test embedding
  csv_file_path = '/content/part13dev1.csv'
  csv_data = np.loadtxt(csv_file_path, delimiter=',')

  original_segments, activities = acc_segmentation(csv_data)

  resampled_segments = [resample_to_30hz_5s(segment, 51.5)[0] for segment in original_segments]

  feature_encoder = load_model()


  embeddings_list = []

  # reshape segments to [n_segments, dimensions(xyz), time]
  x_all = np.transpose( np.array(resampled_segments), (0, 2, 1) )
  print(x_all.shape)

  # iterate over the resampled segments and pass them 
  #    through the model in batches to get the embeddings
  batch_size = 5
  with torch.no_grad():
      for i in range(0, x_all.shape[0], batch_size):
          xb = torch.from_numpy(x_all[i:i+batch_size]).float().to("cpu")
          eb = feature_encoder(xb)  # (B, D_embed)
          embeddings_list.append(eb.cpu().numpy())

  embeddings = np.concatenate(embeddings_list, axis=0)
  print(embeddings.shape)

